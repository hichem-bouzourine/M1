{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZzLUr_l_Wfb"
      },
      "source": [
        "# TP 1 et 2 : Accès aux données avec index\n",
        "# sujet\n",
        "\n",
        "\n",
        "NOM: BOUZOURINE\n",
        "\n",
        "Prénom: HICHEM\n",
        "\n",
        "\n",
        "\n",
        "TP à rendre : **REDIGER des explications détaillées et argumentées** pour les solutions que vous proposez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJrAm4JFr9V"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Objectifs:\n",
        "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
        "\n",
        "Comprendre les méthodes d'accès suivantes :\n",
        "\n",
        "*   Lecture séquentielle d'une fichier : \"table access full\"\n",
        "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
        "*   Opération de sélection par lecture séquentielle et filtrage\n",
        "\n",
        "Comprendre les méthodes d'indexation :\n",
        "\n",
        "*   Créer un index\n",
        "*   Opération de sélection par index et lecture par rowid\n",
        "\n",
        "Mise à jour de données\n",
        "*   Sélectionner un tuple et modifier un de ses attributs\n",
        "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "\n",
        "Persistence\n",
        "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "*   Adapter en conséquence les opérations de modification de l'index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aodlGU01gLqK",
        "outputId": "1ed3a44d-27f5-4086-8354-903df75bc266"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil as sh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# from sortedcontainers import SortedDict\n",
        "import sortedcontainers\n",
        "\n",
        "from string import ascii_lowercase\n",
        "import time\n",
        "\n",
        "# le nom de la table\n",
        "TABLE = \"T\"\n",
        "print(\"le nom de la table est\", TABLE)\n",
        "\n",
        "\n",
        "# le nom du fichier qui contient les données de la table\n",
        "def nom_fichier(table):\n",
        "    return table + \".csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKX2fgx_gYT"
      },
      "source": [
        "# Générer les données du TP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezxoKUCxtASX"
      },
      "source": [
        "Création du fichier contenant un exemple de données.\n",
        "Ce sont des données au format csv. On suppose que chaque ligne correspond à un tuple d'une table **T** ayant *n* attributs :\n",
        "\n",
        "$$ T (a_0, a_1, a_2, ..., a_{n-1})$$\n",
        "\n",
        "Le premier attribut $a_0$ est unique.\n",
        "\n",
        "Les attributs $a_1$ à $a_{n-2}$ ne sont pas uniques : il y a en moyenne $2^k$ tuples par valeurs de $a_k$ soit 2 tuples par valeur de $a_1$ et 4 tuples par valeurs de $a_2$.\n",
        "\n",
        "Les attributs sont des nombres entiers sauf le dernier qui est une chaine de caractères.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIvmnhsTryK4",
        "outputId": "85d2e837-3cf5-478c-c0fd-a8e87eab9e99"
      },
      "outputs": [],
      "source": [
        "# dure environ 20s pour 2M lignes\n",
        "# dure environ 40s pour 5M lignes\n",
        "\n",
        "\n",
        "def genere_fichier(nb_lignes, nb_attributs, longueur_dernier_attribut, table):\n",
        "  # attribut_chaine_caracteres = \"\".join(choice(ascii_lowercase) for i in range(longueur_dernier_attribut))\n",
        "  attribut_chaine_caracteres = ''.join('-' for i in range(longueur_dernier_attribut))\n",
        "  # print(\"le dernier attribut de chaque tuple est la chaine de caracètes :\", attribut_chaine_caracteres)\n",
        "\n",
        "  # reproductibilité des données générées\n",
        "  rng = np.random.default_rng(seed=1)\n",
        "\n",
        "  data={}\n",
        "\n",
        "  # le premier attribut est unique.\n",
        "  nb_valeurs_distinctes = nb_lignes\n",
        "  data['a0'] = 10 * rng.permutation(np.arange(nb_valeurs_distinctes))\n",
        "\n",
        "  # les attributs suivants ont des domaines plus petits :\n",
        "  for i in range(1, nb_attributs):\n",
        "    # on divise le domaine par 2 à chaque itération\n",
        "    nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
        "    data[f'a{i}'] = 10 * rng.integers(0, nb_valeurs_distinctes, nb_lignes)\n",
        "\n",
        "  # on concatène \"verticalement\" les attributs dans un dataframe pour former des tuples sur lesquels on peut itérer.\n",
        "  df = pd.DataFrame(data)\n",
        "  # rmq: le dernier attribut est une chaine de caractères\n",
        "  b = [str(e)[1:-1] + f\",{attribut_chaine_caracteres}\\n\" for e in df.itertuples(index=False, name=None)]\n",
        "\n",
        "  # on stocke les données dans un fichier\n",
        "  fichier = nom_fichier(table)\n",
        "  print(\"écriture des données dans le fichier\", fichier)\n",
        "  with open(fichier, \"w\") as f:\n",
        "    # écriture groupée de tous les tuples\n",
        "    f.write(''.join(b))\n",
        "\n",
        "nb_lignes = 2 * 1000 * 1000\n",
        "# nb_lignes = 5 * 1000 * 1000\n",
        "nb_attributs = 7\n",
        "longueur_dernier_attribut = 100\n",
        "\n",
        "t1 = time.time()\n",
        "genere_fichier(nb_lignes, nb_attributs, longueur_dernier_attribut, TABLE)\n",
        "print(f\"durée pour générer {nb_lignes} lignes :\", round(time.time() - t1, 1), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogkKxanaBHQF"
      },
      "source": [
        "On affiche le début et la fin du fichier et son nombre de lignes ( = card(T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aMC3Y6yryK-",
        "outputId": "ba95e5d7-9bec-468b-96aa-a6dc720a6def"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"{TABLE}.csv\"\n",
        "echo \"debut de $1 :\"\n",
        "head -n 2 $1\n",
        "echo\n",
        "echo \"fin de $1 : \"\n",
        "tail -n 2 $1\n",
        "echo\n",
        "echo \"nombre de lignes:\"\n",
        "wc -l $1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(nom_fichier(TABLE))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gm8_3CY_odp"
      },
      "source": [
        "# Lecture séquentielle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZaYoqeiHO2p"
      },
      "source": [
        "On définit un *iterateur* pour lire séquentiellement chaque ligne de la table stockée entièrement dans un seul fichier.\n",
        "Le mot python *yield* permet de définir un itérateur qui est retourné par la fonction.\n",
        "\n",
        "Cet itérateur est invoqué pour lire la table et appliquer un filtre.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSX2XxLx_tBa",
        "outputId": "59cb964c-8d3a-4063-b429-31a2ec8d9d28"
      },
      "outputs": [],
      "source": [
        "def lecture_sequentielle(table):\n",
        "  fichier = nom_fichier(table)\n",
        "  with open(fichier, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "      yield i, line\n",
        "\n",
        "def filtrer_table(table, valeur_recherchee):\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "      a = int(line.split(',')[0])\n",
        "      if a == valeur_recherchee :\n",
        "        print(f\"ligne {i} :\", line.strip())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nb_valeurs_distinctes = nb_lignes\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_table(TABLE, s)\n",
        "print(\"durée :\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmFE3aZTBWC"
      },
      "source": [
        "# Découper une table en pages\n",
        "\n",
        "On organise les données en pages.\n",
        "Pour faciliter le TP, chaque page est représentée par un \"petit\" fichier mais en réalité une page est un bloc d'un fichier.\n",
        "\n",
        "Dans la suite du TP, on accédera toujours aux pages.\n",
        "Le fichier créé initialement, contenant tous les tuples, ne sera plus utilisé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def page_dir_name(table):\n",
        "  return table + \"_pages\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOEddKG8PHDF",
        "outputId": "983c0891-a68b-466c-fc93-7608fe09fddb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def decoupe_table_en_pages(table, nb_tuple_par_page):\n",
        "  page_dir = page_dir_name(table)\n",
        "\n",
        "  # vider le dossier qui contiendra les pages\n",
        "  if(os.path.exists(page_dir)):\n",
        "    sh.rmtree(page_dir)\n",
        "  os.makedirs(page_dir, exist_ok=True)\n",
        "\n",
        "  # lire le fichier contenant tous les tuples\n",
        "  p=0\n",
        "  lines = []\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "    lines.append(line)\n",
        "    if (i+1) % nb_tuple_par_page == 0:\n",
        "\n",
        "      # créer une page\n",
        "      p += 1\n",
        "      with open(page_dir + f\"/page{p}.csv\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "      lines = []\n",
        "\n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(page_dir + f\"/page{p}.csv\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "\n",
        "  print(\"nb pages créées :\", p)\n",
        "\n",
        "\n",
        "print(\"les pages sont stockées dans le dossier\", page_dir_name(TABLE) )\n",
        "\n",
        "decoupe_table_en_pages(TABLE, nb_tuple_par_page=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqaml72_bXkj"
      },
      "source": [
        "Afficher (pour quelques pages) le nombre de tuples contenus dans une page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('./T_pages/page1.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows,columns =df.shape  \n",
        "print(f'contient : {rows} ligne et {columns} colonne')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMqMNrHbbWof"
      },
      "source": [
        "une solution en bash :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEX48QWEClJD",
        "outputId": "64bf3b18-b763-4a19-e78c-41e196445d3b"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$TABLE\"\n",
        "wc -l $1_pages/* | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3OlZo1ZbToW"
      },
      "source": [
        "une autre solution en python :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99NDkIXsXKrf",
        "outputId": "3cd560aa-39b8-4a51-a9b2-0e0a0eb3d030"
      },
      "outputs": [],
      "source": [
        "page_dir = page_dir_name(TABLE)\n",
        "l = os.listdir(page_dir)\n",
        "random.seed(1)\n",
        "for i in range(3):\n",
        "  une_page = random.choice(l)\n",
        "  with open(page_dir + f\"/{une_page}\", 'r') as fp:\n",
        "    lines = len(fp.readlines())\n",
        "    print(f\"la page {une_page} contient {lines} lignes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4XDZAmbcUQb"
      },
      "source": [
        "# Lecture séquentielle d'une table découpée en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPVOrVpKccUG",
        "outputId": "07a93329-da22-4594-f49f-f10861d2e185"
      },
      "outputs": [],
      "source": [
        "def lecture_sequentielle_par_page(table):\n",
        "  page_dir = page_dir_name(table)\n",
        "  nb_pages = len(os.listdir(page_dir))\n",
        "  for p in range(1, nb_pages+1) :\n",
        "    with open(page_dir + f\"/page{p}.csv\", \"r\") as f:\n",
        "      for i, line in enumerate(f):\n",
        "        tuple_courant = line.strip().split(',')\n",
        "        yield p, i, tuple_courant\n",
        "\n",
        "def filtrer_table_par_pages(table, valeur_recherchee):\n",
        "  for page, position, tuple_courant in lecture_sequentielle_par_page(table):\n",
        "    attribut0 = int(tuple_courant[0])\n",
        "    if attribut0 == valeur_recherchee :\n",
        "      print(f\"page {page}, ligne {position} :\", tuple_courant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "search = np.random.randint(nb_lignes)\n",
        "print(\"valeur recherchée :\", search)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_table_par_pages(TABLE, search)\n",
        "print(\"durée :\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lecture_tuple(table, num_page, position):\n",
        "  page_dir = page_dir_name(table)\n",
        "  with open(page_dir + f\"/page{num_page}.csv\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    return lines[position].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t1 = time.time()\n",
        "print(lecture_tuple(TABLE, 123, 456))\n",
        "print(\"done in\", round((time.time() - t1)*1000, 1), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mD_xZjLxXLD"
      },
      "source": [
        "# Exercice 1 : Créer un index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNgxRQtOTwOH"
      },
      "source": [
        "## Créer un index unique pour l'attribut $a_0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCJyftyiXyFo"
      },
      "source": [
        "On sait que $a_0$ est unique.\n",
        "Une entrée de l'index associe une *clé* à une *valeur* :\n",
        "*   La *clé* est la valeur du premier attribut.\n",
        "*   La *valeur* est un **rowid** formé des informations (page, position)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhy4IJ0bxWHD"
      },
      "outputs": [],
      "source": [
        "def creation_index_unique(table)->sortedcontainers.SortedDict:\n",
        "  index = {}\n",
        "  page_dir = page_dir_name(table)\n",
        "  nb_pages = len(os.listdir(page_dir))\n",
        "  for page, position, tuple_courant in lecture_sequentielle_par_page(table):\n",
        "    a0 = int(tuple_courant[0])\n",
        "    index[a0]= {'page':page,'position':position}     \n",
        "\n",
        "\n",
        "\n",
        "  return sortedcontainers.SortedDict(index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t1 = time.time()\n",
        "INDEX_UNIQUE_a0 = creation_index_unique(TABLE)\n",
        "print(\"durée \", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WbJm39uuwgn"
      },
      "outputs": [],
      "source": [
        "# vérifier l'index\n",
        "s = 10 * np.random.randint(nb_lignes)\n",
        "print(s, INDEX_UNIQUE_a0[s])\n",
        "# print(s, INDEX_UNIQUE_a0[19512870])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcUQ8XRcT1dg"
      },
      "source": [
        "## Créer un index non unique pour l'attribut $a_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4AtpJouWSmB"
      },
      "source": [
        "On donne un nom de table et le numéro $i$ de l'attribut $a_i$ de la table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxJC1-m-VRC5"
      },
      "outputs": [],
      "source": [
        "def creation_index(table, numero_attribut_i)->sortedcontainers.SortedDict:\n",
        "  index = {}\n",
        "  page_dir = page_dir_name(table)\n",
        "  nb_pages = len(os.listdir(page_dir))\n",
        "  for page, position, tuple_courant in lecture_sequentielle_par_page(table):\n",
        "    \n",
        "    ai = int(tuple_courant[numero_attribut_i]) # ai contient le numéro, par exemple 7\n",
        "    # si il dans l'index le rajouter dans la liste : e.g : {7:[{position:2,page:1}]}\n",
        "    # sinon crée une nouvelle liste avec cette élément \n",
        "    # Nom : {ai : [{page:0,position:2},{page:2, position : 1000}]}\n",
        "    ai_position = {'page':page,'position':position}\n",
        "    if(index.get(ai) is None) : \n",
        "      index[ai] = [ai_position]    \n",
        "    else : \n",
        "      index[ai].append(ai_position)\n",
        "      \n",
        "  return sortedcontainers.SortedDict(index)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t1 = time.time()\n",
        "INDEX_a2 = creation_index(TABLE, 2)\n",
        "print(\"duree de création de l'index pour l'attribut a2:\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_a2.get(1235270)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INubLbmNttNJ"
      },
      "outputs": [],
      "source": [
        "# vérifier l'index\n",
        "s = 10 * np.random.randint(nb_valeurs_distinctes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "for r in INDEX_a2[s]:\n",
        "  print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_a2.get(1235270)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qA7hCef5Kfa"
      },
      "source": [
        "# Exerccie 2 : Accès par index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zrHPfGJjzm"
      },
      "source": [
        "## Accès ciblé\n",
        "\n",
        "On veut retrouver les tuples telq qu'un attribut indexé a une valeur donnée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEEUaCYqhIaB"
      },
      "source": [
        "###Index unique scan.\n",
        "On recherche un unique tuple dont l'attribut indexé a une valeur donnée (car l'attribut est unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH3f5bz-5JTu"
      },
      "outputs": [],
      "source": [
        "def acces_par_index_unique(index_unique:object, table:str, valeur_recherchee:int):\n",
        "    position_page = index_unique[valeur_recherchee]\n",
        "    if position_page is None : \n",
        "        return None \n",
        "    # cas indice existe \n",
        "    page,position = position_page['page'],position_page['position']\n",
        "        \n",
        "\n",
        "    return lecture_tuple(table, page, position)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = 10 * np.random.randint(nb_lignes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "tuple = acces_par_index_unique(INDEX_UNIQUE_a0, TABLE, s)\n",
        "print(\"resulat:\", tuple)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfR_0QAShCJi"
      },
      "source": [
        "###Index scan\n",
        "Accès pour rechercher les tuples dont l'attribut indexé a une valeur donnée. On suppose que l'attribut n'est pas unique et que plusieurs tuples sont retrouvés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eyjynk_hZer"
      },
      "outputs": [],
      "source": [
        "def acces_par_index(index, table, valeur_recherchee):\n",
        "    rows = index[valeur_recherchee]\n",
        "    if rows is None : \n",
        "        return [] \n",
        "    # cas indice existe \n",
        "    tuples = []\n",
        "    for row in rows : \n",
        "        page,position = row['page'],row['position']\n",
        "        tuple = lecture_tuple(table, page, position)\n",
        "        tuples.append(tuple)\n",
        "        # yield p, i, tuple_courant\n",
        "    \n",
        "    return tuples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_a2[1385910]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s = 1385910\n",
        "s = 10* np.random.randint(nb_lignes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "for t in acces_par_index(INDEX_a2, TABLE, s):\n",
        "  print(t)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afvN2LWhJs0V"
      },
      "source": [
        "## Accès par intervalle\n",
        "Index range scan\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIL6jrUuaPMO"
      },
      "source": [
        "### Accès par intervalle sur un attribut unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé est unique et a une valeur comprise dans un intervalle donné.\n",
        "Indications, votre solution doit prendre en compte les exigences suivantes :\n",
        "*  Les valeurs recherchées ne sont pas connues à l'avance. On sait seulement qu'elles sont incluses dans un intervalle. Ne pas supposer qu'on recherche des entiers consécutifs.\n",
        "*  Les bornes de l'intervalle ne sont pas parmi les valeurs existantes de l'attribut. Par exemple, on peut rechercher les valeurs de $a_0$ comprises dans l'intervalle  [23 , 45].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8maKd3mdqxKU"
      },
      "outputs": [],
      "source": [
        "# Exemple pour retrouver la première entrée de l'intervalle [23,45]\n",
        "\n",
        "indice = INDEX_UNIQUE_a0.bisect_left(23)\n",
        "print(\"l'indice de la première clé à retrouver est :\", indice)\n",
        "cle = INDEX_UNIQUE_a0.keys()[indice]\n",
        "print(\"la première clé retrouvée est:\", cle)\n",
        "print(\"la valeur à retrouver est :\",  INDEX_UNIQUE_a0[cle])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGEO1PheSEdT"
      },
      "outputs": [],
      "source": [
        "def acces_intervalle_par_index_unique(index_unique:object, table, borne_inf, borne_sup):\n",
        "\n",
        "    indice_inf = index_unique.bisect_left(borne_inf)\n",
        "    indice_sup = index_unique.bisect_right(borne_sup)\n",
        "    tuples = []\n",
        "    while indice_inf<= indice_sup : \n",
        "        cle = index_unique.keys()[indice_inf]\n",
        "        tuple = acces_par_index_unique(index_unique,table,cle)\n",
        "        indice_inf +=1\n",
        "        tuples.append(tuple) # utiliser le yield\n",
        "    return tuples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_UNIQUE_a0[2046210]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = 10 * np.random.randint(nb_valeurs_distinctes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "tuples_indices = acces_intervalle_par_index_unique(INDEX_UNIQUE_a0, TABLE, s + 3, s + 23)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuples_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDaG7WelaQrG"
      },
      "source": [
        "### Accès par intervalle sur un attribut NON unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé n'est **pas** unique et a une valeur comprise dans un intervalle donné.\n",
        "Votre solution doit prendre en compte les mêmes exigences que dans la question précédente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQEYfcoEak5A"
      },
      "outputs": [],
      "source": [
        "def acces_intervalle_par_index(index, table, borne_inf, borne_sup):\n",
        "    indice_inf = INDEX_UNIQUE_a0.bisect_left(borne_inf)\n",
        "    indice_sup = INDEX_UNIQUE_a0.bisect_right(borne_sup)\n",
        "    tuples = []\n",
        "    while indice_inf<= indice_sup : \n",
        "        cle = index.keys()[indice_inf]\n",
        "        # devrait être \n",
        "        # for tuple in  acces_par_index(index,table,cle) # <=== car c'est un yield\n",
        "        tuples_indice = acces_par_index(index,table,cle)\n",
        "        for tuple in tuples_indice : \n",
        "            tuples.append(tuple)\n",
        "        indice_inf +=1\n",
        "    return tuples\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = 10 * np.random.randint(nb_valeurs_distinctes / 4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "acces_intervalle_par_index(INDEX_a2, TABLE, s + 3, s + 33)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rjm99DrKR8t"
      },
      "source": [
        "# Exercice 3 : Mise à jour de données\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7np5NI8OKK6z"
      },
      "source": [
        "## Modifier la valeur d'un attribut d'un ou plusieurs tuples\n",
        "\n",
        "Cela correspond à l'insctruction UPDATE table SET ... WHERE ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7aN87BOuEbq"
      },
      "source": [
        "### Modification d'un seul tuple\n",
        "\n",
        "On donne une valeur *v* de l'attribut clé $a_0$. Ajouter 10 à l'attribut $a_1$. Cela correspond à l'instruction\n",
        "\n",
        "update T\n",
        "set a1 = a1+10\n",
        "where a0 = *v*\n",
        "\n",
        "Après la modification, accéder aux données pour vérifier que le tuple a bien été modifié. Par exemple, invoquer la fonction\n",
        "acces_par_index_unique(index, table, v)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCRwCGlwKlEK"
      },
      "outputs": [],
      "source": [
        "def update_unique(index_unique, table, v)-> bool:\n",
        "    a0= index_unique[v]\n",
        "    if a0 is None: \n",
        "        return  False\n",
        "    page,position = a0['page'],a0['position']\n",
        "    df = pd.read_csv(f'T_pages/page{page}.csv',header=None)\n",
        "    df.at[position,1] =  int(df.iloc[position][1])+10\n",
        "    df.to_csv(f'T_pages/page{page}.csv', header=None,index=False) \n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_UNIQUE_a0.get(19512870)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# before\n",
        "valeur_rechere = 19512870\n",
        "acces_par_index_unique(INDEX_UNIQUE_a0,TABLE,valeur_rechere)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "update_unique(INDEX_UNIQUE_a0,TABLE, valeur_rechere)\n",
        "acces_par_index_unique(INDEX_UNIQUE_a0,TABLE,valeur_rechere)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdexpmRuKfs2"
      },
      "source": [
        "### Modification de plusieurs tuples\n",
        "\n",
        "On donne une valeur *v* de l'attribut $a_2$ qui n'est pas unique. Ajouter 1 à l'attribut $a_3$ de tous les tuples pour lesquels $a_2 = v$\n",
        "\n",
        "update T set a3 = a3+1 where a2=v\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_18vhvxM61d"
      },
      "outputs": [],
      "source": [
        "def update_plusieurs(index, table, v):\n",
        "    rows= index[v]\n",
        "    if rows is None: \n",
        "        return  False\n",
        "    for row in rows : \n",
        "        a2 = row\n",
        "        page,position = a2['page'],a2['position']\n",
        "        df = pd.read_csv(f'T_pages/page{page}.csv',header=None)\n",
        "        df.at[position,3] =  int(df.iloc[position][3])+10\n",
        "        df.to_csv(f'T_pages/page{page}.csv', header=None,index=False) \n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(INDEX_a2.get(1235270))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valeur_rechere_non_unique = 1235270\n",
        "acces_par_index(INDEX_a2,TABLE,valeur_rechere_non_unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "update_plusieurs(INDEX_a2,TABLE,valeur_rechere_non_unique)\n",
        "acces_par_index(INDEX_a2,TABLE,valeur_rechere_non_unique)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zAZws5_KaL8"
      },
      "source": [
        "### Modifier l'index en conséquence lorsque l'attribut modifié est indexé\n",
        "Comerncer par créer un index sur l'attribut $a_3$\n",
        "\n",
        "L'attribut $a_3$ étant maintenant indexé, la mise à jour de la question précédente implique d'actualiser l'index sur $a_3$ pour que les rowid des tuples qui contenaient l'ancienne valeur de $a_3$ soient associés à la nouvelle valeur de $a_3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_dcGN_dKaya"
      },
      "outputs": [],
      "source": [
        "INDEX_a3 = creation_index(TABLE,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_W7xmOKc3l"
      },
      "source": [
        "# Exercice 4 : Persistence\n",
        "\n",
        "Dans cette partie, on veut rendre les index persistents en stockant les entrées triées dans des pages. Cela permet d'utiliser les index plus efficacement en réduisant la durée pour les reconstruire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8NE3x5KgLj"
      },
      "source": [
        "## Stockage d'un index unique\n",
        "\n",
        "Proposez une solution pour stocker les entrées **triées** d'un index dans plusieurs pages avec une taille de page fixée (10 000 rowids par page).\n",
        "Etudier le cas d'un index unique et celui d'un index non unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def index_dir_name(table:str):\n",
        "    return table+\"_index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_a2[150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqSClCOgKl6a"
      },
      "outputs": [],
      "source": [
        "def sauvegarder_index_unique(table:str,index : object,nom_attribut='a0',nb_tuple_par_page=10_000):\n",
        "  index_name = f'{index_dir_name(table)}/{nom_attribut}'\n",
        "\n",
        "  os.makedirs(index_name, exist_ok=True)\n",
        "\n",
        "  # lire le fichier contenant tous les tuples\n",
        "  attributes = ['value','page','position']\n",
        "  \n",
        "  p=0\n",
        "  lines = []\n",
        "  for i, key in enumerate(index.keys()):\n",
        "    # lines.append(line)\n",
        "    \n",
        "    page,position = index[key]['page'],index[key]['position']\n",
        "    lines.append(f'{key},{page},{position}\\n')\n",
        "    if (i+1) % nb_tuple_par_page == 0:\n",
        "\n",
        "      # créer une page\n",
        "      p += 1\n",
        "      with open(f\"{index_name}/page{p}.csv\", \"w\") as fp:\n",
        "        fp.write(','.join(attributes))\n",
        "        fp.write('\\n')\n",
        "        fp.write(''.join(lines))\n",
        "      lines = []\n",
        "\n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(f\"{index_name}/page{p}.csv\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "\n",
        "  print(\"nb pages créées :\", p) \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sauvegarder_index_unique(TABLE,INDEX_UNIQUE_a0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sauvegarder_index(table:str,index : object,nom_attribut='a2',nb_tuple_par_page=10_000):\n",
        "  index_name = f'{index_dir_name(table)}/{nom_attribut}'\n",
        "\n",
        "  os.makedirs(index_name, exist_ok=True)\n",
        "\n",
        "  # lire le fichier contenant tous les tuples\n",
        "  attributes = ['value','page','position']\n",
        "  \n",
        "  p=0\n",
        "  lines = []\n",
        "  for i, key in enumerate(index.keys()):\n",
        "    for row in index[key] : \n",
        "      page,position = row['page'],row['position']\n",
        "      lines.append(f'{key},{page},{position}\\n')\n",
        "      if (i+1) % nb_tuple_par_page == 0:\n",
        "        # créer une page\n",
        "        p += 1\n",
        "        with open(f\"{index_name}/page{p}.csv\", \"w\") as fp:\n",
        "          fp.write(','.join(attributes))\n",
        "          fp.write('\\n')\n",
        "          fp.write(''.join(lines))\n",
        "        lines = []\n",
        "\n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(f\"{index_name}/page{p}.csv\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "\n",
        "  print(\"nb pages créées :\", p) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sauvegarder_index(TABLE,INDEX_a2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EblJsOaluV7"
      },
      "source": [
        "Montrez que vous pouvez reconstruire les index à partir des entrées stockées dans des pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lecture_sequentielle_par_page_index(index_name):\n",
        "  nb_pages = len(os.listdir(index_name))\n",
        "  for p in range(1, nb_pages) :\n",
        "    with open(f\"{index_name}/page{p}.csv\", \"r\") as f:\n",
        "      for i, line in enumerate(f):\n",
        "        if \"value\" not in line : \n",
        "          value,page,position= line.strip().split(',')\n",
        "          yield value,page, position\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxCiuoRRl1IL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def charger_index_unique(table:str,nom_index='a0'):\n",
        "    index = {}\n",
        "    index_name = f'{index_dir_name(table)}/{nom_index}'\n",
        "    if not os.path.exists(index_name) : \n",
        "        return None \n",
        "    for value, page, position in lecture_sequentielle_par_page_index(index_name):\n",
        "        index[int(value)] = {\n",
        "        'page':int(page),'position' : int(position)\n",
        "        }\n",
        "        # print(f\"page {page}, ligne {position} :\", )\n",
        "    return sortedcontainers.SortedDict(index)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index=charger_index_unique(TABLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_UNIQUE_a0[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def charger_index(table:str,nom_index='a2'):\n",
        "    index = {}\n",
        "    index_name = f'{index_dir_name(table)}/{nom_index}'\n",
        "    if not os.path.exists(index_name) : \n",
        "        return None \n",
        "    for value, page, position in lecture_sequentielle_par_page_index(index_name):\n",
        "        position_page = {'page':int(page),'position' : int(position)}\n",
        "        if index.get(int(value)) is None : \n",
        "            index[int(value)] = [position_page]\n",
        "        else :\n",
        "            index[int(value)].append(position_page)\n",
        "        # print(f\"page {page}, ligne {position} :\", )\n",
        "    return sortedcontainers.SortedDict(index)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_a2_chargee = charger_index(TABLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_a2_chargee[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_a2[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDPXcGzKjKU"
      },
      "source": [
        "## Adapter en conséquence les opérations de modification de l'index\n",
        "\n",
        "Illustrer le cas :\n",
        "\n",
        "update T set a3 = a3+0.5 where a1=v\n",
        "\n",
        "où la nouvelle valeur $a_3' = a_3 + 0.5$ n'est pas déjà présente dans l'index. Il faut donc insérer une nouvelle clé  dans l'index de l'attribut $a_3$.\n",
        "On suppose qu'il reste de la place dans une page de l'index pour insérer la nouvelle entrée (on peut avoir jusqu'à 12 000 rowids par page d'index)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9mXqJeFKmUE"
      },
      "outputs": [],
      "source": [
        "def update_index_unique(index_unique, table, v, new_value):\n",
        "    # Lecture de l'index existant\n",
        "    index_name = f'{index_dir_name(table)}/a1'  # Remplacer \"a1\" par le nom de l'attribut correspondant\n",
        "    index = charger_index(index_name)\n",
        "\n",
        "    # Mise à jour de l'index\n",
        "    if index is None:\n",
        "        index = sortedcontainers.SortedDict()\n",
        "\n",
        "    # Supprimer l'ancienne valeur de l'index\n",
        "    if v in index:\n",
        "        del index[v]\n",
        "\n",
        "    # Insérer la nouvelle valeur dans l'index\n",
        "    page, position = INDEX_UNIQUE_a0[new_value]['page'], INDEX_UNIQUE_a0[new_value]['position']\n",
        "    index[new_value] = {'page': page, 'position': position}\n",
        "\n",
        "    # Sauvegarder le nouvel index\n",
        "    sauvegarder_index_unique(table, index, 'a1')  # Remplacer \"a1\" par le nom de l'attribut correspondant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUTS_HFziuGv"
      },
      "source": [
        "# Exercice 5 : Index bitmap\n",
        "*   Proposer un index ayant une structure matricielle (\"bitmap\") pour l'attribut $a_5$. Idem pour l'attribut $a_6$.\n",
        "*   En utilisant les 2 index bitmap, rechercher les tuples de T tels que $a_5 = v_1$ et $a_6 = v_2$ pour deux valeurs $v_1, v_2$ appartenant au domaine de $a_5 \\cap a_6$ .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_UNIQUE_a0.keys()[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_UNIQUE_a0.index(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eiRWHoci4l2"
      },
      "outputs": [],
      "source": [
        "def creation_index_bitmap(table, numero_attribut_i):\n",
        "   return creation_index(table, numero_attribut_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rechercher_tuples(table, index_a5, index_a6):\n",
        "    \n",
        "    # Récupérer l'intersection des domaines de a5 et a6\n",
        "    domain_a5 = set(index_a5.keys())\n",
        "    domain_a6 = set(index_a6.keys())\n",
        "    intersection_domaines = domain_a5.intersection(domain_a6)\n",
        "    \n",
        "    # Parcourir les valeurs possibles dans l'intersection des domaines\n",
        "    for v1 in intersection_domaines:\n",
        "        for v2 in intersection_domaines:\n",
        "            # Récupérer les occurrences de v1 et v2\n",
        "            occurrences_v1 = index_a5.get(v1, [])\n",
        "            occurrences_v2 = index_a6.get(v2, [])\n",
        "            \n",
        "            # Trouver les pages communes\n",
        "            pages_communes = {occurrence['page'] for occurrence in occurrences_v1} & {occurrence['page'] for occurrence in occurrences_v2}\n",
        "            \n",
        "            # Rechercher les tuples sur les pages communes (même position)\n",
        "            for page in pages_communes:\n",
        "                for occurrence_v1 in occurrences_v1:\n",
        "                    if occurrence_v1['page'] == page:\n",
        "                        for occurrence_v2 in occurrences_v2:\n",
        "                            if occurrence_v2['page'] == page and occurrence_v1['position'] == occurrence_v2['position']:\n",
        "                                yield lecture_tuple(table,page,occurrence_v1['position'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_a5_bitmap = creation_index_bitmap(TABLE,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_a6_bitmap = creation_index_bitmap(TABLE,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gen = rechercher_tuples(TABLE,INDEX_a5_bitmap,INDEX_a6_bitmap)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "next(gen)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
