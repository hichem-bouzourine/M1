{"cells":[{"cell_type":"markdown","metadata":{"id":"lwyKqnb61qaM"},"source":["SAM 2024"]},{"cell_type":"markdown","metadata":{"id":"UHqJSxTUdktG"},"source":["#TP10 LSM Store\n","\n","date document: 25/04/2024\n","\n","## BOUZOURINE Hichem"]},{"cell_type":"markdown","metadata":{"id":"Cm43tSzGqzO8"},"source":["L'objectif est de comprendre, par la pratique, les principes du stockage couramment mis en oeuvre dans les systemes big data tels que Cassandra et HBase."]},{"cell_type":"markdown","metadata":{"id":"wUt4Yi2xtp2C"},"source":["## Préparation"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"pt9kszdBH72C"},"outputs":[],"source":["import os\n","import shutil\n","import random\n","import numpy as np\n","import time\n","from sortedcontainers import SortedDict\n","\n","os.makedirs(\"data\", exist_ok=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-3EZ2_nOtjSO"},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: no matches found: *.csv\n"]}],"source":["# !rm -f *.csv"]},{"cell_type":"markdown","metadata":{"id":"fPX7nXiBrO2o"},"source":["# Classe LSM : Log Structured Merge Storage\n","\n","La classe LSM définit les principales fonctions du stockage basé sur LSM."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714114770399,"user":{"displayName":"Hubert Naacke","userId":"03575281438400116050"},"user_tz":-120},"id":"q0EK3t4Zdox9","outputId":"3485b57a-bedb-46ef-d2f1-ef989507b604"},"outputs":[{"name":"stdout","output_type":"stream","text":["class LSM defined\n"]}],"source":["class LSM:\n","  D_MAXSIZE =10\n","\n","\n","  def __init__(self):\n","    self.D = SortedDict()\n","    self.first_image = 0\n","    self.last_image = 0\n","    self.MAX_IMAGE = 2\n","\n","  def set_max_image(self, m):\n","    self.MAX_IMAGE= m\n","\n","\n","  def update(self, k, v):\n","      self.D[k] = v\n","\n","      # vider D dans un fichier si D a atteint sa taille maxi\n","      if len(self.D) == self.D_MAXSIZE:\n","        self.flush_D()\n","        # continuer avec un nouveau D vide\n","        self.D = SortedDict()\n","\n","\n","  def select(self, k):\n","    if k in self.D:\n","      return self.D[k]\n","\n","    # recherche parmi les images du niveau L0\n","    nb_image = self.last_image - self.first_image + 1\n","    for m in range(nb_image):\n","      with open(f\"data/image{self.last_image - m}.csv\", \"r\") as f:\n","        for line in f:\n","          line = line.split(',')\n","          k1,v1 = int(line[0]), int(line[1])\n","          if k1 == k:\n","              return v1\n","\n","    # recherche dans L1\n","    with open(f\"data/L1.csv\", \"r\") as f:\n","      for line in f:\n","        line = line.split(',')\n","        k1, v1 = int(line[0]), int(line[1])\n","        if k1 == k:\n","            return v1\n","    # not found\n","    return \"NULL\"\n","\n","\n","\n","  def flush_D(self):\n","    if self.first_image == 0:\n","      self.first_image = 1\n","\n","    self.last_image +=1\n","\n","    with open(f\"data/image{self.last_image}.csv\", \"w\") as f:\n","      for k, v in self.D.items():\n","          f.write(str(k) + \",\" + str(v) + '\\n')\n","      print(f\"saved {len(self.D)} items in image {self.last_image}\")\n","\n","\n","  def merge_L0_to_L1(self):\n","    # deplace les données de la premiere image de L0 vers le niveau L1\n","    nb_image = self.last_image - self.first_image + 1\n","\n","    if nb_image > self.MAX_IMAGE:\n","      if os.path.isfile(\"data/L1.csv\") :\n","        L1_new = []\n","        L0 = iter(self.read_log(f'image{self.first_image}.csv'))\n","        k0, line0 = next(L0, (None, \"\"))\n","\n","        #fusionner L1 et l'image\n","        for k1, line1 in self.read_log(\"L1.csv\"):\n","          while k0 is not None and k0<=k1:\n","              L1_new.append(line0)\n","              k0, line0 = next(L0, (None, \"\"))\n","          L1_new.append(line1)\n","        print('nb of lines in L1:', len(L1_new))\n","\n","        # créer un nouveau fichier L1 contenant le resultat de la fusion\n","        with open(\"data/L1_new.csv\", 'w') as file_L1_new:\n","          file_L1_new.write(''.join(L1_new))\n","        shutil.move(\"data/L1_new.csv\", \"data/L1.csv\")\n","      else:\n","        # L1 ne contient rien, il suffit de déplacer l'image vers L1\n","        print(f\"move image{self.first_image}.csv to L1.csv\")\n","        shutil.move(f'data/image{self.first_image}.csv', \"data/L1.csv\")\n","      self.first_image +=1\n","\n","\n","  def read_log(self, file):\n","    with open(\"data/\" + file) as f:\n","      for line in f:\n","        key = line.split(',')[0]\n","        yield int(key), line\n","\n","print(\"class LSM defined\")"]},{"cell_type":"markdown","metadata":{"id":"m8lp2ZVRuTAa"},"source":["## Exercice 1"]},{"cell_type":"markdown","metadata":{"id":"0yQsUt2IuWuC"},"source":["Comprendre la classe LSM définie ci dessus"]},{"cell_type":"markdown","metadata":{"id":"tlRIJzVZtu_q"},"source":["## Ecriture de données dans le LSM\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7QFkZ3gTvdIe"},"source":["On effectue un test d'écriture de plusieurs couples dans le LSM"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1714114774078,"user":{"displayName":"Hubert Naacke","userId":"03575281438400116050"},"user_tz":-120},"id":"ifS1DqBTeEVC","outputId":"27e68a59-f8aa-4d10-a067-ed879f76b980"},"outputs":[{"name":"stdout","output_type":"stream","text":["saved 10 items in image 1\n","saved 10 items in image 2\n","saved 10 items in image 3\n","move image1.csv to L1.csv\n","saved 10 items in image 4\n","nb of lines in L1: 20\n","saved 10 items in image 5\n","nb of lines in L1: 30\n","saved 10 items in image 6\n","nb of lines in L1: 39\n","saved 10 items in image 7\n","nb of lines in L1: 47\n","saved 10 items in image 8\n","nb of lines in L1: 56\n","saved 10 items in image 9\n","nb of lines in L1: 66\n","duree 9.0 ms\n"]}],"source":["# on nettoie le dossier ou seront stockés les données\n","shutil.rmtree(\"data\")\n","os.makedirs(\"data\", exist_ok=True)\n","\n","\n","nb_update = 100\n","\n","rng = np.random.default_rng(seed=1)\n","keys = rng.integers(0, 100, nb_update)\n","values = rng.integers(0, 1000, nb_update)\n","\n","store = LSM()\n","\n","store.set_max_image(2)   # remplacer 2 par 4 ?\n","\n","t1 = time.time()\n","for k,v in zip(keys,values):\n","  store.update(k,v)\n","  store.merge_L0_to_L1() # essayer d'enlever cette ligne\n","\n","print(\"duree\", round( (time.time() - t1) * 1000, 0), \"ms\")\n"]},{"cell_type":"markdown","metadata":{"id":"FJgZEn4queny"},"source":["1) Que se passe-t-il si on ajoute\n","store.set_max_image(4) au début du test d'écriture ?"]},{"cell_type":"markdown","metadata":{},"source":["permettre jusqu'à 4 images dans le niveau L0 avant qu'elles ne soient fusionnées dans le niveau L1."]},{"cell_type":"markdown","metadata":{"id":"DtNeDWp4vpDI"},"source":["2) Que se pass-t-il si on enlève la ligne\n","store.merge_L0_to_L1() dans le test?"]},{"cell_type":"markdown","metadata":{},"source":["les données ne seront jamais fusionnées du niveau L0 vers le niveau L1. Cela signifie que toutes les données seront conservées dans le niveau L0 jusqu'à ce que le programme se termine"]},{"cell_type":"markdown","metadata":{"id":"us8UXfOWuUPt"},"source":["## Lecture"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":385,"status":"ok","timestamp":1714114612531,"user":{"displayName":"Hubert Naacke","userId":"03575281438400116050"},"user_tz":-120},"id":"uB0pjeFNg1VJ","outputId":"bfa06a78-e454-41d5-b7f9-2154fc746423"},"outputs":[{"name":"stdout","output_type":"stream","text":["Erreur pour la clé 97 ! La valeur retrouvée (NULL) n'est pas celle attendue (470)\n","Erreur pour la clé 96 ! La valeur retrouvée (NULL) n'est pas celle attendue (885)\n","duree 5.0 ms\n"]}],"source":["# Pour vérifier que la lecture est correcte, on connait à l'avance la valeur la plus récente de chaque k qu'on est censé lire\n","test_D = {}\n","for k,v in zip(keys,values):\n","  test_D[k]=v\n","\n","\n","t1 = time.time()\n","for k,v in test_D.items():\n","    # print(\"select\", k)\n","    v1 = store.select(k)\n","    if v1 != v:\n","      print(f\"Erreur pour la clé {k} ! La valeur retrouvée ({v1}) n'est pas celle attendue ({v})\")\n","\n","print(\"duree\", round( (time.time() - t1) * 1000, 0), \"ms\")\n"]},{"cell_type":"markdown","metadata":{"id":"fkGZG_W20RTa"},"source":["# Exercice 2 : Effet de la fréquence de lecture"]},{"cell_type":"markdown","metadata":{"id":"RjLANIJc0Vut"},"source":["Proposer un test de lecture qui mette en évidence le fait que les clés lues fréquemment (par exemple une lecture toutes les 5 lectures) sont accédées plus rapidement que les clés rares (une lecture toutes les 50 lectures)."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Lecture fréquente: 200\n","Erreur pour la clé 96 ! La valeur retrouvée (NULL) n'est pas celle attendue (885)\n","Erreur pour la clé 96 ! La valeur retrouvée (NULL) n'est pas celle attendue (885)\n","Erreur pour la clé 96 ! La valeur retrouvée (NULL) n'est pas celle attendue (885)\n","Erreur pour la clé 97 ! La valeur retrouvée (NULL) n'est pas celle attendue (470)\n","Erreur pour la clé 97 ! La valeur retrouvée (NULL) n'est pas celle attendue (470)\n","Lecture rare: 20\n","Durée totale de lecture: 12.0 ms\n"]}],"source":["\n","# Configuration des lectures\n","total_reads = 1000\n","freq_frequent_reads = 5  # Lecture fréquente\n","freq_rare_reads = 50     # Lecture rare\n","\n","# Lecture fréquente\n","keys_frequent = np.random.choice(keys, total_reads // freq_frequent_reads)\n","\n","# Lecture rare\n","keys_rare = np.random.choice(keys, total_reads // freq_rare_reads)\n","\n","# Test de lecture\n","t1 = time.time()\n","\n","print(\"Lecture fréquente:\", len(keys_frequent))\n","# Lecture fréquente\n","for k in keys_frequent:\n","    v = test_D[k]\n","    v1 = store.select(k)\n","    if v1 != v:\n","        print(f\"Erreur pour la clé {k} ! La valeur retrouvée ({v1}) n'est pas celle attendue ({v})\")\n","\n","print(\"Lecture rare:\", len(keys_rare))\n","# Lecture rare\n","for k in keys_rare:\n","    v = test_D[k]\n","    v1 = store.select(k)\n","    if v1 != v:\n","        print(f\"Erreur pour la clé {k} ! La valeur retrouvée ({v1}) n'est pas celle attendue ({v})\")\n","\n","print(\"Durée totale de lecture:\", round((time.time() - t1) * 1000, 0), \"ms\")"]},{"cell_type":"markdown","metadata":{"id":"a0E0dFMwttQO"},"source":["# Exercice 3 : Amélioration du stockage du niveau L1"]},{"cell_type":"markdown","metadata":{"id":"P2QPT4iKtvrn"},"source":["On voit que le niveau L1 contient un seul fichier `L1.csv` qui peut grandir indéfiniment.\n","Cela tend à ralentir la recherche d'une clé \"peu fréquente\" qui serait dans le niveau L1.\n","\n","Proposer une classe LSM_v2 pour laquelle le niveau L1 est composé de plusieurs fichiers F1, F2, ... tels que\n","*   chaque fichier contient au maximium N lignes (N= nombre de lignes dans une image),\n","*   les clés sont globalement triées dans les fichiers : toutes les clés du fichier Fi sont inférieures à celles du fichiers Fj (avec i<j)\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hm9lTsFCu2ps"},"outputs":[{"name":"stdout","output_type":"stream","text":["class LSM_v2 defined\n","Saved 10 items in image 1\n","Saved 10 items in image 2\n","Saved 10 items in image 3\n","Saved 10 items in image 4\n","Saved 10 items in image 5\n","Saved 10 items in image 6\n","Saved 10 items in image 7\n","Saved 10 items in image 8\n","Saved 10 items in image 9\n","Durée d'écriture: 9.0 ms\n","Erreur pour la clé 3 ! La valeur retrouvée (873) n'est pas celle attendue (825)\n","Erreur pour la clé 82 ! La valeur retrouvée (555) n'est pas celle attendue (855)\n","Erreur pour la clé 86 ! La valeur retrouvée (479) n'est pas celle attendue (617)\n","Erreur pour la clé 42 ! La valeur retrouvée (81) n'est pas celle attendue (771)\n","Erreur pour la clé 27 ! La valeur retrouvée (219) n'est pas celle attendue (919)\n","Erreur pour la clé 40 ! La valeur retrouvée (861) n'est pas celle attendue (639)\n","Erreur pour la clé 64 ! La valeur retrouvée (840) n'est pas celle attendue (691)\n","Erreur pour la clé 83 ! La valeur retrouvée (919) n'est pas celle attendue (262)\n","Erreur pour la clé 32 ! La valeur retrouvée (645) n'est pas celle attendue (464)\n","Erreur pour la clé 45 ! La valeur retrouvée (253) n'est pas celle attendue (31)\n","Erreur pour la clé 12 ! La valeur retrouvée (413) n'est pas celle attendue (998)\n","Erreur pour la clé 50 ! La valeur retrouvée (976) n'est pas celle attendue (421)\n","Erreur pour la clé 26 ! La valeur retrouvée (963) n'est pas celle attendue (5)\n","Erreur pour la clé 6 ! La valeur retrouvée (42) n'est pas celle attendue (316)\n","Erreur pour la clé 11 ! La valeur retrouvée (796) n'est pas celle attendue (245)\n","Erreur pour la clé 96 ! La valeur retrouvée (589) n'est pas celle attendue (885)\n","Erreur pour la clé 29 ! La valeur retrouvée (489) n'est pas celle attendue (268)\n","Erreur pour la clé 77 ! La valeur retrouvée (314) n'est pas celle attendue (744)\n","Erreur pour la clé 36 ! La valeur retrouvée (871) n'est pas celle attendue (757)\n","Durée de lecture: 10.0 ms\n"]}],"source":["import os\n","import shutil\n","import numpy as np\n","import time\n","from sortedcontainers import SortedDict\n","\n","class LSM_v2:\n","    D_MAXSIZE = 10\n","    MAX_IMAGE = 2\n","    MAX_LINES_PER_FILE = 10\n","\n","    def __init__(self):\n","        self.D = SortedDict()\n","        self.first_image = 0\n","        self.last_image = 0\n","        self.L1_files = []\n","\n","    def set_max_image(self, m):\n","        self.MAX_IMAGE = m\n","\n","    def update(self, k, v):\n","        self.D[k] = v\n","\n","        if len(self.D) == self.D_MAXSIZE:\n","            self.flush_D()\n","            self.D = SortedDict()\n","\n","    def select(self, k):\n","        if k in self.D:\n","            return self.D[k]\n","\n","        # Recherche dans les fichiers L1\n","        for file in self.L1_files:\n","            with open(file, \"r\") as f:\n","                for line in f:\n","                    k1, v1 = map(int, line.strip().split(','))\n","                    if k1 == k:\n","                        return v1\n","\n","        return \"NULL\"\n","\n","    def flush_D(self):\n","        if self.first_image == 0:\n","            self.first_image = 1\n","\n","        self.last_image += 1\n","        image_filename = f\"data/image{self.last_image}.csv\"\n","        with open(image_filename, \"w\") as f:\n","            for k, v in self.D.items():\n","                f.write(f\"{k},{v}\\n\")\n","        print(f\"Saved {len(self.D)} items in image {self.last_image}\")\n","        self.merge_L0_to_L1(image_filename)\n","\n","    def merge_L0_to_L1(self, image_filename):\n","        self.L1_files.append(image_filename)\n","        if len(self.L1_files) > self.MAX_IMAGE:\n","            self.merge_files_L1()\n","\n","    def merge_files_L1(self):\n","        merged_file = []\n","        for file in self.L1_files:\n","            merged_file += self.read_log(file)\n","            os.remove(file)\n","        self.L1_files = []\n","\n","        # Trier les données fusionnées\n","        merged_file.sort(key=lambda x: int(x.split(',')[0]))\n","\n","        # Créer des fichiers L1 avec un maximum de lignes par fichier\n","        num_files = len(merged_file) // self.MAX_LINES_PER_FILE\n","        if len(merged_file) % self.MAX_LINES_PER_FILE != 0:\n","            num_files += 1\n","\n","        for i in range(num_files):\n","            start = i * self.MAX_LINES_PER_FILE\n","            end = min((i + 1) * self.MAX_LINES_PER_FILE, len(merged_file))  # Correction ici\n","            filename = f\"data/L1_{i+1}.csv\"\n","            with open(filename, 'w') as f:\n","                f.writelines(merged_file[start:end])\n","            self.L1_files.append(filename)  # Ajout des nouveaux fichiers à la liste\n","\n","\n","    def read_log(self, file):\n","        with open(file) as f:\n","            return f.readlines()\n","\n","print(\"class LSM_v2 defined\")\n","\n","# Test d'utilisation de la classe LSM_v2\n","shutil.rmtree(\"data\", ignore_errors=True)\n","os.makedirs(\"data\", exist_ok=True)\n","\n","nb_update = 100\n","rng = np.random.default_rng(seed=1)\n","keys = rng.integers(0, 100, nb_update)\n","values = rng.integers(0, 1000, nb_update)\n","\n","store = LSM_v2()\n","store.set_max_image(2)\n","\n","t1 = time.time()\n","for k, v in zip(keys, values):\n","    store.update(k, v)\n","\n","print(\"Durée d'écriture:\", round((time.time() - t1) * 1000, 0), \"ms\")\n","\n","# Test de lecture\n","test_D = {k: v for k, v in zip(keys, values)}\n","\n","t1 = time.time()\n","for k, v in test_D.items():\n","    v1 = store.select(k)\n","    if v1 != v:\n","        print(f\"Erreur pour la clé {k} ! La valeur retrouvée ({v1}) n'est pas celle attendue ({v})\")\n","\n","print(\"Durée de lecture:\", round((time.time() - t1) * 1000, 0), \"ms\")\n"]},{"cell_type":"markdown","metadata":{"id":"88PkS01y2Dax"},"source":["# Exercice 4 : fusion entre plusieurs images"]},{"cell_type":"markdown","metadata":{"id":"OCvE0lcz2ID_"},"source":["On voit que les imagess de L0 sont fusionnées individuellement vers le niveau L1.\n","Proposer une solution pour fusionner k images de L0 vers L1.\n","Indication: tenir compte du fait que les images peuvent contenir des clés identiques."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["class LSM_v2 defined\n","Saved 10 items in image 1\n","Saved 10 items in image 2\n","Saved 10 items in image 3\n","Saved 10 items in image 4\n","Saved 10 items in image 5\n","Saved 10 items in image 6\n","Saved 10 items in image 7\n","Saved 10 items in image 8\n","Saved 10 items in image 9\n","Durée d'écriture: 6.0 ms\n","Durée de lecture: 5.0 ms\n"]}],"source":["import os\n","import shutil\n","import numpy as np\n","import time\n","from sortedcontainers import SortedDict\n","\n","class LSM_v2:\n","    D_MAXSIZE = 10\n","    MAX_IMAGE = 2\n","    MAX_LINES_PER_FILE = 10\n","\n","    def __init__(self):\n","        self.D = SortedDict()\n","        self.first_image = 0\n","        self.last_image = 0\n","        self.L1_files = []\n","\n","    def set_max_image(self, m):\n","        self.MAX_IMAGE = m\n","\n","    def update(self, k, v):\n","        self.D[k] = v\n","\n","        if len(self.D) == self.D_MAXSIZE:\n","            self.flush_D()\n","            self.D = SortedDict()\n","\n","    def select(self, k):\n","        if k in self.D:\n","            return self.D[k]\n","\n","        # Recherche dans les fichiers L1\n","        for file in self.L1_files:\n","            with open(file, \"r\") as f:\n","                for line in f:\n","                    k1, v1 = map(int, line.strip().split(','))\n","                    if k1 == k:\n","                        return v1\n","\n","        return \"NULL\"\n","\n","    def flush_D(self):\n","        if self.first_image == 0:\n","            self.first_image = 1\n","\n","        self.last_image += 1\n","        image_filename = f\"data/image{self.last_image}.csv\"\n","        with open(image_filename, \"w\") as f:\n","            for k, v in self.D.items():\n","                f.write(f\"{k},{v}\\n\")\n","        print(f\"Saved {len(self.D)} items in image {self.last_image}\")\n","        self.merge_L0_to_L1(image_filename)\n","\n","    def merge_L0_to_L1(self, image_filename):\n","        self.L1_files.append(image_filename)\n","        if len(self.L1_files) > self.MAX_IMAGE:\n","            self.merge_files_L1()\n","\n","    def merge_files_L1(self):\n","        merged_file = self.collect_data_from_L0()\n","        if len(merged_file) > 0:\n","            # Trier les données fusionnées\n","            merged_file.sort(key=lambda x: int(x.split(',')[0]))\n","\n","            # Créer des fichiers L1 avec un maximum de lignes par fichier\n","            num_files = len(merged_file) // self.MAX_LINES_PER_FILE\n","            if len(merged_file) % self.MAX_LINES_PER_FILE != 0:\n","                num_files += 1\n","\n","            for i in range(num_files):\n","                start = i * self.MAX_LINES_PER_FILE\n","                end = min((i + 1) * self.MAX_LINES_PER_FILE, len(merged_file))\n","                filename = f\"data/L1_{i+1}.csv\"\n","                with open(filename, 'w') as f:\n","                    f.writelines(merged_file[start:end])\n","                self.L1_files.append(filename)\n","\n","    def collect_data_from_L0(self):\n","        merged_data = {}\n","        for file in self.L1_files:\n","            data = self.read_log(file)\n","            for line in data:\n","                key, value = map(int, line.strip().split(','))\n","                merged_data[key] = value\n","            os.remove(file)\n","        self.L1_files = []\n","        return [f\"{k},{v}\\n\" for k, v in merged_data.items()]\n","\n","    def read_log(self, file):\n","        with open(file) as f:\n","            return f.readlines()\n","\n","print(\"class LSM_v2 defined\")\n","\n","# Test d'utilisation de la classe LSM_v2\n","shutil.rmtree(\"data\", ignore_errors=True)\n","os.makedirs(\"data\", exist_ok=True)\n","\n","nb_update = 100\n","rng = np.random.default_rng(seed=1)\n","keys = rng.integers(0, 100, nb_update)\n","values = rng.integers(0, 1000, nb_update)\n","\n","store = LSM_v2()\n","store.set_max_image(2)\n","\n","t1 = time.time()\n","for k, v in zip(keys, values):\n","    store.update(k, v)\n","\n","print(\"Durée d'écriture:\", round((time.time() - t1) * 1000, 0), \"ms\")\n","\n","# Test de lecture\n","test_D = {k: v for k, v in zip(keys, values)}\n","\n","t1 = time.time()\n","for k, v in test_D.items():\n","    v1 = store.select(k)\n","    if v1 != v:\n","        print(f\"Erreur pour la clé {k} ! La valeur retrouvée ({v1}) n'est pas celle attendue ({v})\")\n","\n","print(\"Durée de lecture:\", round((time.time() - t1) * 1000, 0), \"ms\")\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1KmQTv083OHDT1YDnzKXsUlhEmr1rDQEm","timestamp":1714116620610}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
